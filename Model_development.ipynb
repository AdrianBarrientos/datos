{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model development.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBRegv18JfUx5BH3oKdhEA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RpQ_HsPXrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3kLFo75PbQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Empleados=pd.read_csv(\"https://raw.githubusercontent.com/AlcidesOxa/datos/master/ejemplo.csv\",sep=';',encoding=\"ISO-8859-1\")\n",
        "Empleados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxj7hLdd4MSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cambio={'Años estudio':'Anios_estudio', 'Estado Civil':'Estado_civil', 'Satisfacción Trabajo':'Satisfaccion_trabajo', 'Fecha contrato':'Fecha_contrato'}\n",
        "Empleados.rename(columns=cambio,inplace=True)\n",
        "casosborrar=[3,5,8]\n",
        "Empleados=Empleados.drop(casosborrar)\n",
        "varborrar=['Faltas','Permisos']\n",
        "Empleados=Empleados.drop(varborrar,axis=1)\n",
        "varcategoricas=['Sexo','Estado_civil','Satisfaccion_trabajo']\n",
        "Empleados[varcategoricas]=Empleados[varcategoricas].fillna('Desconocido')\n",
        "Empleados[varcategoricas]=Empleados[varcategoricas].astype('category')\n",
        "Empleados['Fecha_contrato']=pd.to_datetime(Empleados.Fecha_contrato)\n",
        "Empleados['Experiencia_lab']=Empleados.Edad-Empleados.Anios_estudio-5\n",
        "Empleados['Balance']=Empleados.Ingresos-Empleados.Gastos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KARu4LKtfqSQ",
        "colab_type": "text"
      },
      "source": [
        "# Modelo de regresión lineal múltiple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_36Bh-BSptOI",
        "colab_type": "text"
      },
      "source": [
        "El modelo clásico de regresión lineal múltiple es una técnica estadística, que permite explorar y confirmar relaciones lineales entre una variable de interés (dependiente) y un conjunto de variables explicativas (independientes), o predictoras de la variable dependiente. La relación no es completamente determinística, se admite un componente aleatorio o de perturbación, que captura la parte aleatoria de la variable dependiente, y que no es atribuible a las variables explicativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwztLp3bqNaA",
        "colab_type": "text"
      },
      "source": [
        "La especificación del modelo es\n",
        "\\begin{equation*}\n",
        "Y_{i}=\\beta _{1}+\\beta _{2}X_{i2}+\\beta _{3}X_{i3}+\\ldots +\\beta\n",
        "_{k}X_{ik}+u_{i}\n",
        "\\end{equation*}\n",
        "donde $Y_{i}$ ($i=1,2,\\ldots ,n$) es la variable dependiente; $X_{i2}$, $X_{i3}$, $\\ldots $, $X_{ik}$ son las variables explicativas; $\\beta _{1}$, $\\beta _{2}$, $\\ldots $, $\\beta _{k}$ son parámetros, con $\\beta _{1}$ como la parte constante de $Y_{i}$ que no varía con las explictivas, también conocido como sesgo; $\\beta _{2}$, $\\ldots $, $\\beta _{k}$ relacionan a la variable dependiente con las explicativas respectivas; y $u_{i}$ es un término de perturbación aleatoria.\n",
        "\n",
        "El modelo en notación matricial es\n",
        "\\begin{eqnarray*}\n",
        "Y &=&X\\beta +u \\\\\n",
        "\\begin{pmatrix}\n",
        "Y_{1} \\\\ \n",
        "Y_{2} \\\\ \n",
        "\\vdots  \\\\ \n",
        "Y_{n}\n",
        "\\end{pmatrix}\n",
        "&=&\n",
        "\\begin{pmatrix}\n",
        "1 & X_{12} & \\ldots  & X_{1k} \\\\ \n",
        "1 & X_{22} & \\ldots  & X_{2k} \\\\ \n",
        "\\vdots  & \\vdots  & \\ddots  & \\vdots  \\\\ \n",
        "1 & X_{n2} & \\ldots  & X_{nk}\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "\\beta _{1} \\\\ \n",
        "\\beta _{2} \\\\ \n",
        "\\vdots  \\\\ \n",
        "\\beta _{k}\n",
        "\\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "u_{1} \\\\ \n",
        "u_{2} \\\\ \n",
        "\\vdots  \\\\ \n",
        "u_{n}\n",
        "\\end{pmatrix}\n",
        "\\end{eqnarray*}\n",
        "donde $n$ es el tamaño de la muestra, $k$ el número de variables y $n>k$. En la práctica, el vector de parámetros $β$ es desconocido. El objetivo es estimarlo a partir de una muestra aleatoria proveniente de la población objeto de estudio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOqp89FTJCOA",
        "colab_type": "text"
      },
      "source": [
        "## Variables del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4HPjzv9veUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vars_mod = ['Ingresos', 'Edad', 'Sexo', 'Anios_estudio', 'Estado_civil']\n",
        "vars_cat_mod = ['Sexo', 'Estado_civil']\n",
        "vars_cuant_mod = ['Edad', 'Anios_estudio']\n",
        "Datos = Empleados[vars_mod].dropna()\n",
        "Datos.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCBiVy-mxATZ",
        "colab_type": "text"
      },
      "source": [
        "## Análisis gráfico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD7hhPMpxGUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(Datos.Edad,Datos.Ingresos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVAWKF4GWUoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(Datos.Anios_estudio,Datos.Ingresos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQSywdiAmYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.plotting.scatter_matrix(Datos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD51W24zqHPX",
        "colab_type": "text"
      },
      "source": [
        "## Estimación por MCO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBMp5T3itTnm",
        "colab_type": "text"
      },
      "source": [
        "La contraparte muestral de $Y=X\\beta +u$ con un estimador $\\widehat{\\beta }$ a determinar es\n",
        "\\begin{eqnarray*}\n",
        "Y=X\\widehat{\\beta }+\\widehat{u}\n",
        "\\end{eqnarray*}\n",
        "y dado que tampoco se conoce $u$ se reemplaza por $\\widehat{u}$. Aplicando la técnica de mínimos cuadrados ordinarios (MCO) se obtiene derivando parcialmente la suma de cuadrados $\\widehat{u}^{\\prime }\\widehat{u}$ con respecto a los elementos del vector $\\widehat{\\beta }$ e igualando a $0$ (vector de ceros) para optimizar\n",
        "\\begin{eqnarray*}\n",
        "\\frac{\\partial \\widehat{u}^{\\prime }\\widehat{u}}{\\partial \\widehat{\\beta }}=\n",
        "\\frac{\\partial }{\\partial \\widehat{\\beta }}\\left( Y-X\\widehat{\\beta }\\right)\n",
        "^{\\prime }\\left( Y-X\\widehat{\\beta }\\right) =-2X^{\\prime }\\left( Y-X\\widehat{\n",
        "\\beta }\\right) =0\n",
        "\\end{eqnarray*}\n",
        "resolviendo ésta ecuación para $\\widehat{\\beta }$ se tiene el\n",
        "estimador por MCO\n",
        "\\begin{eqnarray*}\n",
        "\\widehat{\\beta }=\\left( X^{\\prime }X\\right) ^{-1}X^{\\prime }Y\n",
        "\\end{eqnarray*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGcnoNNTqGlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = Datos[vars_cuant_mod]\n",
        "Y = Datos.Ingresos\n",
        "reg = LinearRegression()\n",
        "modelo1 = reg.fit(X,Y)\n",
        "print(modelo1.coef_, ' ', modelo1.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIh_oo2DuzXr",
        "colab_type": "text"
      },
      "source": [
        "## Bondad de ajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9cahn4Su4Az",
        "colab_type": "text"
      },
      "source": [
        "El ajuste del modelo a los datos se mide por el coeficiente de determinación\n",
        "\\begin{equation*}\n",
        "R^{2}=1-\\frac{\\sum_{i=1}^{n}\\widehat{u}_{i}^{2}}{\\sum_{i=1}^{n}\\left( Y_{i}-\\overline{Y}\\right) ^{2}}\n",
        "\\end{equation*}\n",
        "donde $\\overline{Y}=\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}$ es la media de la variable dependiente. Este coeficiente varía entre 0 y 1, si tiende a 0 entonces el modelo no se ajusta bien a los datos, por el contrario si se acerca a 1 entonces el ajuste es bueno. No obstante el $R^{2}$ no es un indicador adecuado sobre el ajuste del modelo fuera de la muestra de estimación, dado que es una función creciente de la cantidad de variables\n",
        "explicativas, y puede aumentar aún con variables predictoras superfluas.\n",
        "Como alternativa se propone el $R^{2}$ ajustado\n",
        "\\begin{equation*}\n",
        "\\overline{R}^{2}=1-\\frac{n-1}{n-k}\\left( 1-R^{2}\\right) \n",
        "\\end{equation*}\n",
        "cuya interpretación es similar al del $R^{2}$, pero lo bueno es que las variables explicativas innecesarias no tienden a incrementarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmLsOCHlJNVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R2 = modelo1.score(X,Y)\n",
        "n, k = np.shape(X)\n",
        "k = k + 1\n",
        "R2a = 1 - (n-1)/(n-k)*(1-R2)\n",
        "print(R2,' ',R2a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHkDp6IaK5uL",
        "colab_type": "text"
      },
      "source": [
        "## Predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skUluIOU7V3R",
        "colab_type": "text"
      },
      "source": [
        "La predicción de los valores de la media condicional de la variable dependiente es $\\widehat{Y}=X\\widehat{\\beta }$. Para medir la incertidumbre de éstas predicciones se tiene la matriz de covarianzas de $\\widehat{Y}$, y su estimación es\n",
        "\\begin{equation*}\n",
        "\\widehat{\\Sigma }_{\\widehat{y}}=\\widehat{\\sigma }^{2}X\\left( X^{\\prime\n",
        "}X\\right) ^{-1}X^{\\prime }\n",
        "\\end{equation*}\n",
        "Para evaluar las predicciones se aplica el error cuadrático medio (MSE por sus siglas en inglés) el cual es, en general, para cualquier estimación o predicción $\\widehat{\\theta }$\n",
        "\\begin{equation*}\n",
        "MSE\\left( \\widehat{\\theta }\\right) =E\\left[ \\left( \\widehat{\\theta }-\\theta \\right) ^{2}\\right]\n",
        "\\end{equation*}\n",
        "Para las predicciones del modelo de regresión lineal, el MSE es\n",
        "\\begin{equation*}\n",
        "MSE\\left( \\widehat{Y}\\right)=\\frac{\\sum_{i=1}^{n}\\left( Y_i-\\widehat{Y_i} \\right) ^{2}}{n}=\\frac{\\sum_{i=1}^{n}\\widehat{u}_{i}^{2}}{n}\n",
        "\\end{equation*}\n",
        "Mayores valores del MSE indican que los errores son grandes en la predicción, por el contrario, valores bajos indican una mejor predicción. En muchos casos se utiliza la raíz cuadrada del MSE para evaluar las predicciones, y entonces se habla del RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTn6upSDuseF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Yp = modelo1.predict(X)\n",
        "print('MSE', mean_squared_error(Y,Yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SMLv0lSXh2D",
        "colab_type": "text"
      },
      "source": [
        "# Regresión polinómica y Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uwa3F-HcnJm",
        "colab_type": "text"
      },
      "source": [
        "## Términos polinomiales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RhtoulmaLo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = [[3, 2], [5, 8]]\n",
        "PolynomialFeatures(2).fit_transform(W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WihnMdKPJWKj",
        "colab_type": "text"
      },
      "source": [
        "## Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxbjITa3zIbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe1 = Pipeline([\n",
        "                  ('estand', StandardScaler()),\n",
        "                  ('polin', PolynomialFeatures()),\n",
        "                  ('reglin', LinearRegression())\n",
        "])\n",
        "pipe1.fit(X, Y)\n",
        "pipe1.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WndFLzU2fc_6",
        "colab_type": "text"
      },
      "source": [
        "# Regresión con variables explicativas cualitativas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3oFQP2Gfv8j",
        "colab_type": "text"
      },
      "source": [
        "## Obtención de las variables dicotómicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkZgJl-Sx4yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dicos = pd.get_dummies(Datos[vars_cat_mod], drop_first = True)\n",
        "X = pd.concat([Dicos, Datos[vars_cuant_mod]], axis=1)\n",
        "Y = Datos.Ingresos\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34QWua5BKXW4",
        "colab_type": "text"
      },
      "source": [
        "## Ajuste lineal y predicción"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vkf7SDCA09-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg = LinearRegression()\n",
        "modelo1 = reg.fit(X,Y)\n",
        "Yp = modelo1.predict(X)\n",
        "print('MSE', mean_squared_error(Y,Yp), '-- Score', modelo1.score(X,Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc62LBPBgC0B",
        "colab_type": "text"
      },
      "source": [
        "# Regresión con variables dicotómicas y polinomiales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKsOeIAkKid8",
        "colab_type": "text"
      },
      "source": [
        "## Regresiones polinómicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3v9J0ADEVoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,4):\n",
        "  X = PolynomialFeatures(i).fit_transform(Datos[vars_cuant_mod])\n",
        "  X = pd.DataFrame(X, index = Dicos.index.values)\n",
        "  X = pd.concat([Dicos, X], axis=1)\n",
        "  m1 = reg.fit(X, Y)\n",
        "  Yp = m1.predict(X)\n",
        "  print(mean_squared_error(Y, Yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRUQmsHRKtMG",
        "colab_type": "text"
      },
      "source": [
        "## Regresiones polinómicas y evaluación fuera de la muestra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW1nsDY4QdPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DatosPrb = pd.DataFrame([[6240, 43, 'Hombre', 11, 'Casado(a)']], columns = vars_mod)\n",
        "Datos_EP = pd.concat([Datos, DatosPrb], keys = ['Entr', 'Prb'])\n",
        "Dicos_EP = pd.get_dummies(Datos_EP[vars_cat_mod], drop_first = True)\n",
        "Y_e = Datos_EP.Ingresos.loc['Entr',:]\n",
        "Y_p = Datos_EP.Ingresos.loc['Prb',:]\n",
        "for i in range(1,4):\n",
        "  X = PolynomialFeatures(i).fit_transform(Datos_EP[vars_cuant_mod])\n",
        "  X = pd.DataFrame(X, index = Dicos_EP.index.values)\n",
        "  X = pd.concat([Dicos_EP, X], axis=1)\n",
        "  X_e = X.loc['Entr',:]\n",
        "  X_p = X.loc['Prb',:]\n",
        "  m1 = reg.fit(X_e, Y_e)\n",
        "  Yp = m1.predict(X_p)\n",
        "  print(mean_squared_error(Y_p, Yp))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}